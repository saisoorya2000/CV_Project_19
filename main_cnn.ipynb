{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from data_loader.ipynb\n",
      "importing Jupyter notebook from va_cnn_model.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import import_ipynb\n",
    "from data_loader import NTUDataloader\n",
    "from va_cnn_model import VA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    model = VA(60)\n",
    "    model = model.cuda()\n",
    "    \n",
    "    # We train each stream of view adaptive neural network by minimizing the cross-entropy loss end-to-end. \n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "    \n",
    "    # Adam is adapted to train all networks, and the initial learning rate is set to 0.0001 for all datasets\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    \n",
    "    loader = NTUDataloader()\n",
    "    train_loader = loader.train_data_loader()\n",
    "    val_loader = loader.val_data_loader()\n",
    "    # print(train_loader)\n",
    "    max_epochs = 10\n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        \n",
    "        # running_loss = 0\n",
    "#         tot = 0\n",
    "#         count = 0\n",
    "        # get the inputs data is a list of [inputs, maxmin, labels]\n",
    "        model.train()\n",
    "        for i,data in enumerate(train_loader):\n",
    "            inputs, maxmin, outlabels = data\n",
    "            \n",
    "            # forward + backward + optimize\n",
    "            outputs, image, params = model(inputs.cuda(), maxmin.cuda())\n",
    "            outlabels = outlabels.cuda()\n",
    "            loss = criterion(outputs, outlabels)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "#             count += inputs.size(0)\n",
    "#             batch_size = outlabels.size(0)\n",
    "#             _, pred = outputs.topk(1, 1, True, True)\n",
    "#             pred = pred.t()\n",
    "#             correct = pred.eq(outlabels.view(1, -1).expand_as(pred))\n",
    "#             correct = correct.view(-1).float().sum(0, keepdim=True)\n",
    "#             acc =  correct.mul_(100.0 / batch_size)\n",
    "#             tot = acc*batch_size\n",
    "# #             print(acc.cpu().numpy())\n",
    "#             print('Epoch-{:<3d}' 'Accuracy {accuracy:.4f}'.format(epoch + 1, accuracy=acc.cpu().numpy()[0]))  \n",
    "\n",
    "            # calculating loss and accuracy\n",
    "            # running_loss += loss.item()\n",
    "        \n",
    "            if (i+1) % 200 == 0:    # print every 10 mini-batches\n",
    "                print('Epoch-{:<3d} {:3d} batches\\t'\n",
    "                      'loss {loss:.4f}'.format(\n",
    "                       epoch + 1, i + 1,loss=loss))\n",
    "            \n",
    "        validate(val_loader, model, criterion, epoch)\n",
    "\n",
    "    print('Finished Training')\n",
    "    print('')\n",
    "    print('Now Testing')\n",
    "    test_loader = loader.test_data_loader()\n",
    "    test(test_loader, model, criterion)\n",
    "    \n",
    "    \n",
    "def validate(val_loader, model, criterion, epoch):\n",
    "    model.eval()\n",
    "    tot = 0\n",
    "    count = 0\n",
    "    for i,data in enumerate(val_loader):\n",
    "        inputs, maxmin, outlabels = data\n",
    "            \n",
    "        # forward + backward + optimize\n",
    "        with torch.no_grad():\n",
    "            outputs, image, params = model(inputs.cuda(), maxmin.cuda())\n",
    "        outlabels = outlabels.cuda()\n",
    "        with torch.no_grad():\n",
    "            loss = criterion(outputs, outlabels)\n",
    "        count += inputs.size(0)\n",
    "        batch_size = outlabels.size(0)\n",
    "        _, pred = outputs.topk(1, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(outlabels.view(1, -1).expand_as(pred))\n",
    "        correct = correct.view(-1).float().sum(0, keepdim=True)\n",
    "        acc =  correct.mul_(100.0 / batch_size)\n",
    "        tot += acc.cpu().numpy()[0]*batch_size\n",
    "    print('')\n",
    "    print('Validation: Epoch-{:<3d}' 'Accuracy {accuracy:.4f}'.format(epoch + 1, accuracy=tot/count))        \n",
    "    print('')\n",
    "    \n",
    "def test(test_loader, model, criterion):\n",
    "    model.eval()\n",
    "    tot = 0\n",
    "    count = 0\n",
    "    for i,data in enumerate(test_loader):\n",
    "        inputs, maxmin, outlabels = data\n",
    "            \n",
    "        # forward + backward + optimize\n",
    "        with torch.no_grad():\n",
    "            outputs, image, params = model(inputs.cuda(), maxmin.cuda())\n",
    "        outlabels = outlabels.cuda()\n",
    "        with torch.no_grad():\n",
    "            loss = criterion(outputs, outlabels)\n",
    "        count += inputs.size(0)\n",
    "        batch_size = outlabels.size(0)\n",
    "        _, pred = outputs.topk(1, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(outlabels.view(1, -1).expand_as(pred))\n",
    "        correct = correct.view(-1).float().sum(0, keepdim=True)\n",
    "        acc =  correct.mul_(100.0 / batch_size)\n",
    "        tot += acc.cpu().numpy()[0]*batch_size\n",
    "    print('')\n",
    "    print('Testing: Total-{:<3d}' '  Accuracy {accuracy:.4f}'.format(count, accuracy=tot/count))        \n",
    "    print('')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38086, 300, 150)\n",
      "(16487, 300, 150)\n",
      "Epoch-1   200 batches\tloss 2.1145\n",
      "Epoch-1   400 batches\tloss 1.3451\n",
      "Epoch-1   600 batches\tloss 1.3268\n",
      "Epoch-1   800 batches\tloss 1.0231\n",
      "Epoch-1   1000 batches\tloss 0.7354\n",
      "\n",
      "Validation: Epoch-1  Accuracy 69.8753\n",
      "\n",
      "Epoch-2   200 batches\tloss 0.8353\n",
      "Epoch-2   400 batches\tloss 0.3947\n",
      "Epoch-2   600 batches\tloss 0.5571\n",
      "Epoch-2   800 batches\tloss 0.5922\n",
      "Epoch-2   1000 batches\tloss 0.7208\n",
      "\n",
      "Validation: Epoch-2  Accuracy 71.8204\n",
      "\n",
      "Epoch-3   200 batches\tloss 1.2502\n",
      "Epoch-3   400 batches\tloss 0.4216\n",
      "Epoch-3   600 batches\tloss 0.4066\n",
      "Epoch-3   800 batches\tloss 0.8972\n",
      "Epoch-3   1000 batches\tloss 0.4500\n",
      "\n",
      "Validation: Epoch-3  Accuracy 72.8678\n",
      "\n",
      "Epoch-4   200 batches\tloss 0.3949\n",
      "Epoch-4   400 batches\tloss 0.2627\n",
      "Epoch-4   600 batches\tloss 0.5583\n",
      "Epoch-4   800 batches\tloss 0.4016\n",
      "Epoch-4   1000 batches\tloss 0.5577\n",
      "\n",
      "Validation: Epoch-4  Accuracy 78.6035\n",
      "\n",
      "Epoch-5   200 batches\tloss 0.4768\n",
      "Epoch-5   400 batches\tloss 0.2661\n",
      "Epoch-5   600 batches\tloss 0.1614\n",
      "Epoch-5   800 batches\tloss 0.3812\n",
      "Epoch-5   1000 batches\tloss 0.1272\n",
      "\n",
      "Validation: Epoch-5  Accuracy 79.6010\n",
      "\n",
      "Epoch-6   200 batches\tloss 0.1210\n",
      "Epoch-6   400 batches\tloss 0.3452\n",
      "Epoch-6   600 batches\tloss 0.2643\n",
      "Epoch-6   800 batches\tloss 0.1829\n",
      "Epoch-6   1000 batches\tloss 0.0884\n",
      "\n",
      "Validation: Epoch-6  Accuracy 81.7955\n",
      "\n",
      "Epoch-7   200 batches\tloss 0.1701\n",
      "Epoch-7   400 batches\tloss 0.2180\n",
      "Epoch-7   600 batches\tloss 0.2563\n",
      "Epoch-7   800 batches\tloss 0.0443\n",
      "Epoch-7   1000 batches\tloss 0.1873\n",
      "\n",
      "Validation: Epoch-7  Accuracy 84.0399\n",
      "\n",
      "Epoch-8   200 batches\tloss 0.1382\n",
      "Epoch-8   400 batches\tloss 0.3313\n",
      "Epoch-8   600 batches\tloss 0.2649\n",
      "Epoch-8   800 batches\tloss 0.1151\n",
      "Epoch-8   1000 batches\tloss 0.1126\n",
      "\n",
      "Validation: Epoch-8  Accuracy 82.2943\n",
      "\n",
      "Epoch-9   200 batches\tloss 0.1472\n",
      "Epoch-9   400 batches\tloss 0.2149\n",
      "Epoch-9   600 batches\tloss 0.1807\n",
      "Epoch-9   800 batches\tloss 0.1934\n",
      "Epoch-9   1000 batches\tloss 0.3367\n",
      "\n",
      "Validation: Epoch-9  Accuracy 81.8953\n",
      "\n",
      "Epoch-10  200 batches\tloss 0.2325\n",
      "Epoch-10  400 batches\tloss 0.0224\n",
      "Epoch-10  600 batches\tloss 0.0576\n",
      "Epoch-10  800 batches\tloss 0.2862\n",
      "Epoch-10  1000 batches\tloss 0.4126\n",
      "\n",
      "Validation: Epoch-10 Accuracy 84.6384\n",
      "\n",
      "Finished Training\n",
      "\n",
      "Now Testing\n",
      "\n",
      "Testing: Total-16487  Accuracy 80.7060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
